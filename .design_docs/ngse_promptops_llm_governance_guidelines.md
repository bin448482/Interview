# NGSE 项目中的 PromptOps / LLM 审核 / Prompt QA 笔记

> 场景：Zoetis NGSE（Next Generation Sales Engine）中国区落地  
> 目标：在合规前提下，把生成式 AI（Sales Copilot）做成“工程化、可治理”的能力，而不是零散 Prompt 拼接

---

## 1. 什么是 PromptOps？

可以类比 DevOps，只不过对象从「代码」变成了「Prompt + LLM 能力」。

核心理念：把 Prompt 当成一等公民的产品资产来管理。

- 有规范  
  - 每个 Prompt 有名称 / 版本号 / Owner / 适用场景说明  
  - 记录依赖的模型（如 Azure OpenAI、GLM）和关键参数（温度、最大 Tokens 等）
- 有流程  
  - 需求 → Prompt 设计 → 评审（合规 / 风险）→ 上线 → 监控 → 复盘  
  - 与常规交付流程（发布窗口、变更记录）打通，而不是线下口头改
- 有数据和工具  
  - 记录每次调用的输入、输出、模型版本、延迟、错误码  
  - 做简单报表：哪个 Prompt 使用最多、失败率最高、被投诉最多
- 有治理节奏  
  - 定期 Prompt 评审会：看命中率、投诉、合规风险  
  - 把“好 Prompt”沉淀为模板，支持其他项目复用

在 NGSE 中的作用：  
确保 Sales Copilot 的提示词、推荐逻辑有版本、可追溯、可持续优化，而不是“隐形逻辑”。

---

## 2. LLM 审核如何做？

不是让模型“自我审查”，而是对使用 LLM 的场景、输入输出和流程进行多层审核。

### 2.1 场景级审核

- 明确“允许用 LLM”的场景  
  - 例如：销售摘要、本周重点、下一步建议、风险提示
- 明确“禁止用 LLM”的场景  
  - 例如：最终价格决策、合规红线判断、医疗/用药建议

### 2.2 输入/输出规则

- 输入侧  
  - 数据必须来自 DDP/数仓治理层，禁止直连原始系统  
  - 对人名、电话、身份证等个人敏感信息要脱敏或屏蔽  
  - 不允许把内部密级过高的信息发给外部 API 模型
- 输出侧  
  - 不得对疗效、价格做过度承诺  
  - 要避免违反公司合规/营销政策的表述  
  - 输出中应明确“建议性质”，避免被误解为“强制指令”

### 2.3 人工抽检 + 关键词告警

- 人工抽检  
  - 定期抽样对话/推荐结果，标记为「合规 / 存疑 / 不合规」  
  - 对“不合规/高风险”案例进行复盘，更新 Prompt / 规则
- 关键词告警  
  - 对涉及折扣、回扣、敏感疾病、监管风险的关键词设置监控  
  - 一旦触发，自动打标或报警给风险/合规负责人

### 2.4 流程与可追溯性

- 重要 Prompt 上线前有简单评审记录（评审人、日期、风险结论）
- 一旦发生合规事件，可追溯：  
  - 使用的是哪个 Prompt 版本  
  - 调用了哪个模型版本  
  - 对话上下文是什么

---

## 3. 什么是 Prompt QA？

Prompt QA = Prompt 的质量测试 + 回归测试。

### 3.1 测试数据集

- 设定一批固定的测试输入  
  - 典型客户画像、典型区域、典型销售问题  
  - 包含“边界情况”和“容易出错的案例”
- 每次改 Prompt 或换模型时，用同一批输入跑一遍

### 3.2 评估维度

- 业务正确性  
  - 推荐是否符合业务逻辑（不能推荐库存为 0 的产品）  
  - 内容是否覆盖必要字段（客户、区域、时间、产品线等）
- 可读性与可执行性  
  - 输出是否清晰、易执行（有明确“下一步动作”）  
  - 风格是否符合公司话术规范
- 风险与合规  
  - 是否含有敏感承诺、违规表述  
  - 是否没有越权给出用药/医疗类建议

可以给每条测试样本打简单分数，例如：

- 业务相关性：1–5  
- 可执行性：1–5  
- 风险等级：低 / 中 / 高

### 3.3 回归和对比

- 每次 Prompt 调整前后，对比：  
  - 命中率是否提升  
  - 风险样本是否减少  
  - 是否出现新的严重退化（例如以前能识别的风险点现在识别不了）
- 只有在总体评分不降、风险不升的前提下，才允许新 Prompt 上线

---

## 4. NGSE 项目里的整体闭环

在 NGSE 中国区落地中，这三件事串起来就是：

1. 用 PromptOps 管理 Sales Copilot 的提示词和推荐逻辑（有版本、有流程、有数据）  
2. 用 LLM 审核定义清晰的“能用 / 不能用”边界，并对高风险场景做额外保护  
3. 用 Prompt QA 做日常的质量评估和回归测试，避免“改一次 Prompt 搞坏一大片”

最终目标：  
在中国数据出入境和合规要求下，把生成式 AI 变成一个可控、可解释、有指标的平台能力，而不是一个黑盒玩具。

