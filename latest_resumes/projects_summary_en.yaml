schema_version: 1.1
generated_at: '2025-11-28T10:40:46.354834'
source_file: Resume_Data_Engineer_CN_20250529.md
projects:
- project_name: MySixth Tarot Card Intelligent Application
  company_or_context: Zoetis / Individual Independent Developer
  timeframe:
    label: October 2025 - Present
    start: 2025-10
    end: null
  role_title: Independent developer
  role_perspective: hybrid
  management_scope:
    team_size: 1
    budget_level: lt_100k
    stakeholder_tiers:
    - customer
    - ops
  decision_accountability:
  - delivery_owner
  - technical_strategy
  - hands_on_build
  - commercial_strategy
  - risk_governance
  responsibility_focus:
  - planning
  - architecture
  - implementation
  - commercialization
  - stakeholder_management
  impact_metrics:
    business_metrics:
    - 'Q4 2025 paid conversion 18% (+50% vs. industry benchmark) with 6% DAU pay-through
      and RMB 60K ARR locked in by day 60.'
    - 'Cohort telemetry surfaced high-value spreads and boosted repeat purchase funnel
      completion by 12 percentage points.'
    technical_metrics:
    - 'Unified LLM factory + cost dashboard lowered AI call cost by 60% while keeping
      TP99 inference under 1.2s.'
    - 'Event bus + cohort dashboards visualize experiment deltas within 24 hours
      to support prompt/paywall tests.'
    operational_metrics:
    - 'Single cloud server deployment keeps monthly operating cost under RMB 500.'
    - 'Android/iOS/Web/Admin suite ships once with shared release automation to accelerate
      cadence.'
    - 'A/B cycle <2 days with feedback loops closed within 48 hours.'
  governance_artifacts:
  - runbook
  - prompt_playbook
  - cost_dashboard
  - ab_test_matrix
  project_overview: 'TarotAI omnichannel kit (Expo React Native app + FastAPI backend
    + Next.js admin + AI content generator) layered with product telemetry, cohort
    dashboards, and prompt governance so anonymous users get a four-step tarot journey
    plus paid AI readings. GitHub: https://github.com/bin448482/tarotAI'
  data_domain: Consumer-level Tarot Fortune Telling / AI Content Operation
  ai_component_flag: true
  challenges_or_objectives:
  - Deliver mobile, backend, admin, and AI generator assets as a solo builder while
    still reserving capacity for PM rituals.
  - Merge user interviews + funnel telemetry into roadmap choices so anonymous identity,
    offline sync, and multi-channel payments line up in one architecture.
  - Build a two-phase AI pipeline, multi-LLM routing, and cost guardrails under a
    unified dashboard.
  - Design subscription/IAP/redemption monetization and codify prompt governance
    plus experimentation guardrails.
  responsibilities:
  - 'Lead four-surface architecture: Expo mobile, FastAPI services, Next.js admin,
    AI batch generator.'
  - 'Define north star metrics (conversion, retention), maintain experiment backlog,
    user interviews, and prioritization cadences.'
  - Design anonymous installation ID + JWT authentication, four-step divination flow,
    and end-to-end API contract.
  - Implement Google Play IAP/redemption/Stripe (reserved) charging routes, revenue
    share reports, and risk controls.
  - Set up Docker Compose + Nginx deployment, monitoring, and offline backups while
    chairing prompt governance and risk reviews.
  - Publish multilingual README/CLAUDE guides and telemetry SOPs to institutionalize
    build + operate processes.
  architecture_or_solution:
  - Expo RN (SDK54) client + FastAPI monolith + Next.js 15 admin + Python AI generator
    layered architecture.
  - 'Dual-stage AI API: `/readings/analyze` for recommendations, `/readings/generate`
    for paid narratives, backed by prompt audit trail.'
  - 'Anonymous identity: `installation_id` + optional email binding + JWT access,
    plus session enrichment for cohort tagging.'
  - 'Offline-first: Expo SQLite `tarot_config.db` preload + sync strategy, backend
    SQLite persistence.'
  - 'Payments: Google Play Billing, bulk redemption codes, reserved Stripe Checkout
    with revenue share dashboards.'
  - Docker Compose (backend/admin/nginx) + Nginx route split.
  - 'AI content ops: `tarot-ai-generator` Typer CLI linking SQLite + GLM-4/OpenAI/Ollama
    for batch copy with spend monitors.'
  - 'Product telemetry: PostHog/Amplitude events feed cohort + retention dashboards
    and experiment decisions.'
  process_or_methodology:
  - Vibe coding / modular components + Expo Router four-step flow.
  - OKR → north star metrics → hypothesis backlog → A/B validation cadence layered
    onto TypeScript/Python coding standards.
  - Offline sync + SQLite versioning + Docker volume backups.
  - EAS Build + CI/CD + multi-environment `.env` governance.
  - Doc-driven development (README/CLAUDE) + prompt governance reviews.
  - Weekly user interviews/feedback tagging feeding the experiment matrix.
  deliverables_or_features:
  - 'Expo mobile app `my-tarot-app`: spreads, AI paid readings, history, icon pipeline.'
  - 'FastAPI `tarot-backend`: LLM gateway, payments, admin APIs, static assets, health
    checks.'
  - 'Next.js `tarot-admin-web`: dashboards, user/points ops, bulk code generation,
    order tracking, client download portal.'
  - 'Tarot AI Generator: multimode batch generation, multilingual routing, JSON import/export.'
  - 'Product telemetry + cohort dashboards: funnel/retention/pay analysis with cost/revenue
    reconciliation.'
  - 'Prompt governance pack: templates, risk checklist, A/B log, cost ceilings.'
  - Nginx + Docker Compose deployment topology, offline SQLite backup manual.
  - "Monetization strategy: IAP first → redemption/Stripe fallback with anonymous identity compatibility."
  metrics_or_impact:
  - Production suite running on Android/iOS/Web/Admin.
  - Two-stage AI narrative lifts conversion and achieves 34% month-2 retention.
  - Anonymous identity + offline cache enables journeys without registration or
    strong connectivity.
  - Dockerized delivery shortens environment setup, SQLite backup lowers ops risk.
  - Experiment matrix surfaced high-value spreads, improving monthly retention by
    12 pts and ARR by RMB 18K.
  tech_stack:
  - Expo React Native (SDK 54 / React Native 0.81)
  - TypeScript 5.x
  - Next.js 15 App Router + Ant Design 6 + Tailwind CSS
  - FastAPI 0.104 + SQLAlchemy + Uvicorn
  - SQLite (Expo/Backend)
  - Python 3.10 + Typer CLI
  - GLM-4 (ZhiPuAI)
  - OpenAI API
  - Ollama/Claude (removable)
  - LangChain / Self-developed LLM Router
  - Docker & Docker Compose
  - Nginx Proxy
  - Google Play Billing / Stripe Checkout (Reserved)
  tools_platforms:
  - Expo Router 6
  - Status + SWR
  - EAS Construction
  - Ant Design Charts
  - ESLint / Pylint / Prettier
  - CI/CD Pipeline + generate-icons.js script
  - Docker volume backup solution
  team_info:
    team_size: 1
    description: Personal independent development + AI collaboration + multi-warehouse
      document-driven
  notes: 'See tarotAI repo (Expo app, FastAPI backend, Next.js admin, AI generator,
    Docker/Nginx) plus user interview and prompt governance notes. GitHub: https://github.com/bin448482/tarotAI'
- project_name: NGSE (Next Generation Sales Engine)
  company_or_context: Zoetis
  timeframe:
    label: 2023.6 - 2025.9
    start: 2023-06
    end: 2025-09
  role_title: Project Manager & Data Architect & Generative AI Product Lead
  role_perspective: hybrid
  management_scope:
    team_size: 5
    budget_level: gt_1m
    stakeholder_tiers:
    - exec
    - director
    - ops
    - vendor
  decision_accountability:
  - delivery_owner
  - technical_strategy
  - people_management
  - risk_governance
  - commercial_strategy
  responsibility_focus:
  - planning
  - architecture
  - stakeholder_management
  - compliance
  - commercialization
  impact_metrics:
    business_metrics:
    - Sales playbooks + AI opportunity recommendations reached 82% adoption and delivered RMB 28M ARR uplift.
    - Regional pipeline visibility improved 35% with exec dashboard NPS +40.
    technical_metrics:
    - Key report runtime improved 2-3x while LLM summaries stay under 4 seconds of latency.
    - Data accuracy hit 99.5% to power AI training and multi-market reuse.
    operational_metrics:
    - Enterprise lakehouse + experiment handbook scaled to additional markets.
    - LLM review + prompt QA flow cut risk defect closure time by 45%.
  governance_artifacts:
  - exec_dashboard
  - risk_register
  - prompt_playbook
  - ai_policy
  project_overview: Led China-region NGSE data + AI product transformation, building a Databricks lakehouse, sales copilot capability, and prompt governance so sales/marketing teams can align pipeline insight, run experiments, and quantify monetization.
  data_domain: Global Sales Engine / Data Platform
  ai_component_flag: true
  challenges_or_objectives:
  - Build a standardized data platform and extend it into a generative AI copilot.
  - Balance multi-market data reliability with rapid AI experimentation.
  - Establish prompt/compliance governance that satisfies risk, medical, and regional regulators.
  responsibilities:
  - Design data pipelines integrated with the Azure ecosystem while owning the AI product roadmap.
  - Define data quality, monitoring, performance strategies, and north star metrics/experiment funnels.
  - Build lakehouse + notebook templates + prompt QA checklists for market reuse.
  - Run ADF scheduling, cross-platform data transfer, and AI cost/revenue dashboards.
  - Align executives, chair risk reviews, prompt audits, and monetization retrospectives.
  architecture_or_solution:
  - Four-layer data architecture: Inbox→Raw→Transform→Governed.
  - Databricks Workflows + Delta Lake for dependency + ACID management.
  - Incremental strategy validating T-1 deltas with LLM quality hooks.
  - Spark SQL/PySpark shared ETL modules + method registry.
  - Parameterized notebooks linked with ADF for multi-market reuse.
  - Sales Copilot: LLM summaries, next-best-actions, risk alerts, and chat embedded in Power BI.
  process_or_methodology:
  - Lakehouse + PromptOps dual governance.
  - Modularized/atomized data development standards + dual-track boards tracking experiments.
  - Automated data quality, anomaly alerts, and prompt reviews.
  - Biweekly OKR/roadmap reviews plus experiment/risk alignment forums.
  deliverables_or_features:
  - Cross-platform data transmission link (Aliyun OSS→ADLS Gen2).
  - Schema drift/field integrity/null duplication monitoring.
  - Hot wide table partitioning, Z-ordering, caching, dynamic aggregation.
  - Sales Copilot workspace: opportunity summaries, next-step recommendations, prompt QA panel.
  - Exec dashboards + ARR/opportunity funnel + prompt cost board.
  metrics_or_impact:
  - Report runtime improved 2-3x.
  - Company lakehouse + prompt governance templates replicated across four markets.
  - AI recommendation hit rate 70%, saving sellers six hours per week on lead prep.
  - Zero high-severity risk escalations; compliance audits passed on first attempt.
  tech_stack:
  - Databricks
  - Delta Lake
  - Azure Data Factory
  - Azure Storage
  - Spark SQL
  - PySpark
  - Azure Functions
  - Power BI + Fabric
  - Azure OpenAI / GLM API
  tools_platforms:
  - Databricks Workflows
  - ADF
  - Azure Data Lake Storage Gen2
  - Prompt QA toolkit
  team_info:
    team_size: 5
    description: Cross-market squad mixing PO, data engineers, analysts.
  notes: Owned China market roadmap + PromptOps governance adopted as a global reference.
- project_name: Remedium (BI)
  company_or_context: Portable Water Craft
  timeframe:
    label: 2016.10 - 2023.02
    start: 2016-10
    end: 2023-02
  role_title: Technical Team Leader
  role_perspective: architect
  management_scope:
    team_size: null
    budget_level: null
    stakeholder_tiers:
    - exec
    - director
    - ops
    - regulator
  decision_accountability:
  - delivery_owner
  - technical_strategy
  - risk_governance
  responsibility_focus:
  - architecture
  - stakeholder_management
  - compliance
  impact_metrics:
    business_metrics:
    - User satisfaction reached 95% and passed all compliance audits.
    technical_metrics:
    - Data processing time reduced by 30%.
    - Data quality improved to 99.9%
    operational_metrics:
    - Establish a 24-hour cross-border collaboration rhythm.
  governance_artifacts:
  - training_plan
  - risk_register
  project_overview: A BI solution tailored for the pharmaceutical industry, covering
    data pipeline, report analysis, and web portal.
  data_domain: Pharmaceutical Industry BI
  ai_component_flag: false
  challenges_or_objectives:
  - Design scalable solution architecture
  - Enhance data processing efficiency and reporting timeliness.
  - Enhance business personnel's review experience.
  responsibilities:
  - Design and coordinate cross-border teams.
  - Supervise ADF + Databricks data pipeline development
  - Guidance Report/Implementation of Analysis Layer and Portal Design
  - Promote cross-functional communication
  architecture_or_solution:
  - ADF Pipeline + Databricks Processing Framework
  - Web portal improves review efficiency
  process_or_methodology:
  - Cross-team collaboration and solution review
  deliverables_or_features:
  - Trading data reporting system
  - Remedium Web Portal
  metrics_or_impact:
  - Processing time reduced, data quality improved.
  - Enhanced real-time access to improve problem-solving efficiency.
  - Gained positive feedback from stakeholders.
  tech_stack:
  - Azure Data Factory
  - Databricks
  - BI Tools
  - Web technology
  tools_platforms:
  - Azure Ecosystem
  team_info:
    team_size: null
    description: Cross-border team collaboration
  notes: null
